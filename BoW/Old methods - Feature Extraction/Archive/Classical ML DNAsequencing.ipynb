{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2580,
     "status": "ok",
     "timestamp": 1616682704760,
     "user": {
      "displayName": "Swiss Baz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXzlrRV6mp31muOP9-SkG2Bqe4yaRqjFrtEvNyUzQ=s64",
      "userId": "00750900217968553970"
     },
     "user_tz": -60
    },
    "id": "wV50vkA7hETb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import timeit\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, plot_confusion_matrix\n",
    "from scipy import sparse\n",
    "import seaborn as sn\n",
    "from joblib import dump, load\n",
    "import multiprocessing as mp\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1616682704761,
     "user": {
      "displayName": "Swiss Baz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXzlrRV6mp31muOP9-SkG2Bqe4yaRqjFrtEvNyUzQ=s64",
      "userId": "00750900217968553970"
     },
     "user_tz": -60
    },
    "id": "mGsQk7QFhETi"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "def importLabels():\n",
    "#     with open('./Data/shortlabels.txt', 'r') as filehandle:\n",
    "    with open('./Data/labels.txt', 'r') as filehandle:\n",
    "\n",
    "\n",
    "        for line in filehandle:\n",
    "            # remove linebreak, if exists, which is the last character of the string\n",
    "            if(line[-1] == \"\\n\"):\n",
    "                currentPlace = line[:-1]\n",
    "            else:\n",
    "                currentPlace = line[:]\n",
    "            # add item to the list\n",
    "            labels.append(currentPlace)\n",
    "importLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Kmer counts DFs data  from disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAAA</th>\n",
       "      <th>AAAAAC</th>\n",
       "      <th>AAAAAG</th>\n",
       "      <th>AAAAAT</th>\n",
       "      <th>AAAACA</th>\n",
       "      <th>AAAACC</th>\n",
       "      <th>AAAACG</th>\n",
       "      <th>AAAACT</th>\n",
       "      <th>AAAAGA</th>\n",
       "      <th>AAAAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTCG</th>\n",
       "      <th>TTTTCT</th>\n",
       "      <th>TTTTGA</th>\n",
       "      <th>TTTTGC</th>\n",
       "      <th>TTTTGG</th>\n",
       "      <th>TTTTGT</th>\n",
       "      <th>TTTTTA</th>\n",
       "      <th>TTTTTC</th>\n",
       "      <th>TTTTTG</th>\n",
       "      <th>TTTTTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAAAA  AAAAAC  AAAAAG  AAAAAT  AAAACA  AAAACC  AAAACG  AAAACT  AAAAGA  \\\n",
       "0         6.0     6.0     3.0     3.0     2.0     5.0     3.0     6.0     4.0   \n",
       "1         2.0     NaN     2.0     NaN     2.0     NaN     NaN     NaN     3.0   \n",
       "2         NaN     NaN     4.0     2.0     2.0     NaN     2.0     NaN     NaN   \n",
       "3         3.0     NaN     2.0     2.0     2.0     NaN     NaN     NaN     2.0   \n",
       "4         2.0     2.0     2.0     3.0     3.0     2.0     2.0     NaN     3.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995     3.0     2.0     NaN     3.0     NaN     5.0     NaN     NaN     NaN   \n",
       "59996     NaN     NaN     2.0     4.0     NaN     2.0     2.0     2.0     NaN   \n",
       "59997     NaN     NaN     4.0     2.0     4.0     2.0     2.0     3.0     4.0   \n",
       "59998     3.0     NaN     NaN     NaN     4.0     NaN     2.0     2.0     2.0   \n",
       "59999     2.0     4.0     2.0     2.0     4.0     2.0     7.0     NaN     2.0   \n",
       "\n",
       "       AAAAGC  ...  TTTTCG  TTTTCT  TTTTGA  TTTTGC  TTTTGG  TTTTGT  TTTTTA  \\\n",
       "0         3.0  ...     NaN     3.0     3.0     3.0     3.0     3.0     NaN   \n",
       "1         NaN  ...     2.0     4.0     NaN     NaN     2.0     2.0     3.0   \n",
       "2         6.0  ...     5.0     NaN     2.0     3.0     4.0     NaN     3.0   \n",
       "3         3.0  ...     2.0     NaN     NaN     NaN     2.0     3.0     NaN   \n",
       "4         2.0  ...     NaN     2.0     3.0     NaN     2.0     3.0     2.0   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995     NaN  ...     3.0     3.0     3.0     NaN     NaN     2.0     5.0   \n",
       "59996     NaN  ...     2.0     NaN     NaN     NaN     NaN     3.0     4.0   \n",
       "59997     2.0  ...     NaN     3.0     NaN     2.0     NaN     3.0     2.0   \n",
       "59998     NaN  ...     2.0     5.0     5.0     2.0     2.0     NaN     NaN   \n",
       "59999     4.0  ...     3.0     NaN     2.0     2.0     8.0     4.0     3.0   \n",
       "\n",
       "       TTTTTC  TTTTTG  TTTTTT  \n",
       "0         4.0     5.0     4.0  \n",
       "1         2.0     NaN     3.0  \n",
       "2         5.0     NaN     4.0  \n",
       "3         2.0     NaN     NaN  \n",
       "4         NaN     2.0     NaN  \n",
       "...       ...     ...     ...  \n",
       "59995     NaN     2.0     3.0  \n",
       "59996     5.0     NaN     NaN  \n",
       "59997     2.0     2.0     3.0  \n",
       "59998     4.0     2.0     NaN  \n",
       "59999     NaN     4.0     5.0  \n",
       "\n",
       "[60000 rows x 4096 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=7\n",
    "#Data generated with old code\n",
    "# Xt = pd.read_pickle(r\"D:\\DataSet\\Data\\Generated kmers with old py code\\4-5-Kmers-60,000 samples\")\n",
    "\n",
    "# data generated with Linux kmer counter code, 4-5-6-kmers\n",
    "# Xt = pd.read_pickle(r\"D:\\DataSet\\Data\\Generated kmers with old py code\\4-5-Kmers-60,000 samples\")\n",
    "\n",
    "# X = pd.read_feather(r\"D:\\DataSet\\df-k\"+str(k)+\".feather\")\n",
    "# X=pd.DataFrame()\n",
    "# Xt5=pd.DataFrame()\n",
    "X = pd.read_feather(r\"D:\\DataSet\\MULTI\\bow\\10k-df-k6part-0.feather\")\n",
    "# p2 = pd.read_feather(r\"D:\\DataSet\\MULTI\\bow\\10k-df-k7part-1.feather\")\n",
    "# p3 = pd.read_feather(r\"D:\\DataSet\\MULTI\\bow\\10k-df-k7part-2.feather\")\n",
    "\n",
    "for i in range(1,6):\n",
    "    p = pd.read_feather(r\"D:\\DataSet\\MULTI\\bow\\10k-df-k6part-\"+str(i) +r\".feather\")\n",
    "#     p5 = pd.read_feather(r\"D:\\DataSet\\MULTI\\bow\\10k-df-k5part-\"+str(i) +r\".feather\")\n",
    "\n",
    "    X = pd.concat([X, p], ignore_index=True)\n",
    "#     Xt5 = pd.concat([Xt5, p5], ignore_index=True)\n",
    "    \n",
    "# X = pd.concat([Xt6, Xt5], axis=1)#, ignore_index=True)\n",
    "# X= pd.concat([Xt, p3], ignore_index=True)\n",
    "# X= pd.concat([p1,p2, p3], ignore_index=True)\n",
    "\n",
    "\n",
    "# X.loc[,:]\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAAA</th>\n",
       "      <th>AAAAAC</th>\n",
       "      <th>AAAAAG</th>\n",
       "      <th>AAAAAT</th>\n",
       "      <th>AAAACA</th>\n",
       "      <th>AAAACC</th>\n",
       "      <th>AAAACG</th>\n",
       "      <th>AAAACT</th>\n",
       "      <th>AAAAGA</th>\n",
       "      <th>AAAAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTCG</th>\n",
       "      <th>TTTTCT</th>\n",
       "      <th>TTTTGA</th>\n",
       "      <th>TTTTGC</th>\n",
       "      <th>TTTTGG</th>\n",
       "      <th>TTTTGT</th>\n",
       "      <th>TTTTTA</th>\n",
       "      <th>TTTTTC</th>\n",
       "      <th>TTTTTG</th>\n",
       "      <th>TTTTTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAAAA  AAAAAC  AAAAAG  AAAAAT  AAAACA  AAAACC  AAAACG  AAAACT  AAAAGA  \\\n",
       "0           6       6       3       3       2       5       3       6       4   \n",
       "1           2       0       2       0       2       0       0       0       3   \n",
       "2           0       0       4       2       2       0       2       0       0   \n",
       "3           3       0       2       2       2       0       0       0       2   \n",
       "4           2       2       2       3       3       2       2       0       3   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       3       2       0       3       0       5       0       0       0   \n",
       "59996       0       0       2       4       0       2       2       2       0   \n",
       "59997       0       0       4       2       4       2       2       3       4   \n",
       "59998       3       0       0       0       4       0       2       2       2   \n",
       "59999       2       4       2       2       4       2       7       0       2   \n",
       "\n",
       "       AAAAGC  ...  TTTTCG  TTTTCT  TTTTGA  TTTTGC  TTTTGG  TTTTGT  TTTTTA  \\\n",
       "0           3  ...       0       3       3       3       3       3       0   \n",
       "1           0  ...       2       4       0       0       2       2       3   \n",
       "2           6  ...       5       0       2       3       4       0       3   \n",
       "3           3  ...       2       0       0       0       2       3       0   \n",
       "4           2  ...       0       2       3       0       2       3       2   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       0  ...       3       3       3       0       0       2       5   \n",
       "59996       0  ...       2       0       0       0       0       3       4   \n",
       "59997       2  ...       0       3       0       2       0       3       2   \n",
       "59998       0  ...       2       5       5       2       2       0       0   \n",
       "59999       4  ...       3       0       2       2       8       4       3   \n",
       "\n",
       "       TTTTTC  TTTTTG  TTTTTT  \n",
       "0           4       5       4  \n",
       "1           2       0       3  \n",
       "2           5       0       4  \n",
       "3           2       0       0  \n",
       "4           0       2       0  \n",
       "...       ...     ...     ...  \n",
       "59995       0       2       3  \n",
       "59996       5       0       0  \n",
       "59997       2       2       3  \n",
       "59998       4       2       0  \n",
       "59999       0       4       5  \n",
       "\n",
       "[60000 rows x 4096 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.fillna(0, inplace=True)\n",
    "X = X.astype(int)\n",
    "display(X)\n",
    "\n",
    "# labels = []\n",
    "# importLabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data from BagOfWords to Tf-Idf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Select best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CachedDF = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAAA</th>\n",
       "      <th>AAAAAC</th>\n",
       "      <th>AAAAAG</th>\n",
       "      <th>AAAAAT</th>\n",
       "      <th>AAAACA</th>\n",
       "      <th>AAAACC</th>\n",
       "      <th>AAAACG</th>\n",
       "      <th>AAAACT</th>\n",
       "      <th>AAAAGA</th>\n",
       "      <th>AAAAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTCG</th>\n",
       "      <th>TTTTCT</th>\n",
       "      <th>TTTTGA</th>\n",
       "      <th>TTTTGC</th>\n",
       "      <th>TTTTGG</th>\n",
       "      <th>TTTTGT</th>\n",
       "      <th>TTTTTA</th>\n",
       "      <th>TTTTTC</th>\n",
       "      <th>TTTTTG</th>\n",
       "      <th>TTTTTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAAAA  AAAAAC  AAAAAG  AAAAAT  AAAACA  AAAACC  AAAACG  AAAACT  AAAAGA  \\\n",
       "0           6       6       3       3       2       5       3       6       4   \n",
       "1           2       0       2       0       2       0       0       0       3   \n",
       "2           0       0       4       2       2       0       2       0       0   \n",
       "3           3       0       2       2       2       0       0       0       2   \n",
       "4           2       2       2       3       3       2       2       0       3   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       3       2       0       3       0       5       0       0       0   \n",
       "59996       0       0       2       4       0       2       2       2       0   \n",
       "59997       0       0       4       2       4       2       2       3       4   \n",
       "59998       3       0       0       0       4       0       2       2       2   \n",
       "59999       2       4       2       2       4       2       7       0       2   \n",
       "\n",
       "       AAAAGC  ...  TTTTCG  TTTTCT  TTTTGA  TTTTGC  TTTTGG  TTTTGT  TTTTTA  \\\n",
       "0           3  ...       0       3       3       3       3       3       0   \n",
       "1           0  ...       2       4       0       0       2       2       3   \n",
       "2           6  ...       5       0       2       3       4       0       3   \n",
       "3           3  ...       2       0       0       0       2       3       0   \n",
       "4           2  ...       0       2       3       0       2       3       2   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       0  ...       3       3       3       0       0       2       5   \n",
       "59996       0  ...       2       0       0       0       0       3       4   \n",
       "59997       2  ...       0       3       0       2       0       3       2   \n",
       "59998       0  ...       2       5       5       2       2       0       0   \n",
       "59999       4  ...       3       0       2       2       8       4       3   \n",
       "\n",
       "       TTTTTC  TTTTTG  TTTTTT  \n",
       "0           4       5       4  \n",
       "1           2       0       3  \n",
       "2           5       0       4  \n",
       "3           2       0       0  \n",
       "4           0       2       0  \n",
       "...       ...     ...     ...  \n",
       "59995       0       2       3  \n",
       "59996       5       0       0  \n",
       "59997       2       2       3  \n",
       "59998       4       2       0  \n",
       "59999       0       4       5  \n",
       "\n",
       "[60000 rows x 4096 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = CachedDF\n",
    "# X =  X.astype(int)\n",
    "# X"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "selector = SelectPercentile(score_func=chi2, percentile=50) \n",
    "# selector = SelectKBest(chi2, k=1000)\n",
    "X = selector.fit_transform(X, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          5669  3462\n",
      "1          3178  5691\n",
      "accuracy = 0.631 \n",
      "precision = 0.631 \n",
      "recall = 0.631 \n",
      "f1 = 0.631\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=420) # If using tf-idf vector, just replace X_cv with X1.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Calculate accuracy rate, recall rate, and f1\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(pd.crosstab(pd.Series(Y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "def get_metrics(Y_test, y_predicted):\n",
    "    accuracy = accuracy_score(Y_test, y_predicted)\n",
    "    precision = precision_score(Y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(Y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(Y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(Y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of kmer counting is {end - start} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of GridSearch HyperParam tuning of GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
      "                                       ('clf', MultinomialNB())]),\n",
      "             param_grid={'clf__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 1e-05)},\n",
      "             return_train_score=True)classifier is 0.0009996891021728516 secs\n",
      "Runtime of fitting GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
      "                                       ('clf', MultinomialNB())]),\n",
      "             param_grid={'clf__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 1e-05)},\n",
      "             return_train_score=True)classifier is 120.86841297149658 secs\n",
      "{'clf__alpha': 0.1}\n",
      "Pipeline(steps=[('scale', MinMaxScaler()), ('clf', MultinomialNB(alpha=0.1))])\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "SVCpipe = Pipeline([('scale', MinMaxScaler()),\n",
    "                   ('clf',MultinomialNB())])\n",
    "param_grid = {'clf__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)}   \n",
    "# defining parameter range\n",
    "  \n",
    "clf = GridSearchCV(SVCpipe,param_grid,cv=5,return_train_score=True)\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of GridSearch HyperParam tuning of \"+ str(clf)+ f\"classifier is {end - start} secs\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of fitting \"+ str(clf)+ f\"classifier is {end - start} secs\")\n",
    "\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(clf.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(clf.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.632 \n",
      "precision = 0.633 \n",
      "recall = 0.632 \n",
      "f1 = 0.632\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "# print(\"Confusion matrix\\n\")\n",
    "def get_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_abs_scaler = MaxAbsScaler()\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xEE5bPF0hETo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 4096)\n",
      "(6000, 4096)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    labels, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1616679221401,
     "user": {
      "displayName": "Swiss Baz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXzlrRV6mp31muOP9-SkG2Bqe4yaRqjFrtEvNyUzQ=s64",
      "userId": "00750900217968553970"
     },
     "user_tz": -60
    },
    "id": "IGD7jnJOhETo",
    "outputId": "1d699fd7-64c8-4469-debf-4f618fcd3397"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(),GaussianNB()) ## Bad performance on kmers 4-5\n",
    "# clf=  make_pipeline(StandardScaler(),LogisticRegression(random_state=0, max_iter=40000).fit(X_train, y_train))\n",
    "\n",
    "# clf=  make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5, C=0.01, max_iter=2500))# Hyper Tuned\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "# clf = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', random_state=10))\n",
    "# clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=4, random_state=0))\n",
    "# clf = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of fitting \"+ str(clf)+ f\"classifier is {end - start} secs\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p_test3 = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,250,500,750,1000,1250,1500,1750]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test3, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p_test2 = {'max_depth':[2,3,4,5,6,7] }\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.01,n_estimators=1500, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test2, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('gaussiannb', GaussianNB())])classifier is 29.668682098388672 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.53      0.56      0.54      1533\n",
    "           1       0.51      0.48      0.49      1467\n",
    "\n",
    "    accuracy                           0.52      3000\n",
    "   macro avg       0.52      0.52      0.52      3000\n",
    "weighted avg       0.52      0.52      0.52      3000\n",
    "\n",
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('linearsvc',\n",
    "                 LinearSVC(C=0.01, max_iter=2500, random_state=0, tol=1e-05))])classifier is 998.8032536506653 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.59      0.58      0.58      1533\n",
    "           1       0.57      0.58      0.57      1467\n",
    "\n",
    "    accuracy                           0.58      3000\n",
    "   macro avg       0.58      0.58      0.58      3000\n",
    "weighted avg       0.58      0.58      0.58      3000\n",
    "\n",
    "\n",
    "# gradientboostingclassifier with k =7\n",
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('gradientboostingclassifier',\n",
    "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
    "                                            random_state=0))])classifier is 3012.994718313217 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.66      0.66      0.66      1533\n",
    "           1       0.65      0.65      0.65      1467\n",
    "\n",
    "    accuracy                           0.66      3000\n",
    "   macro avg       0.65      0.65      0.65      3000\n",
    "weighted avg       0.66      0.66      0.66      3000\n",
    "\n",
    "\n",
    "# gradientboostingclassifier with k = 5 and 6\n",
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('gradientboostingclassifier',\n",
    "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=1,\n",
    "                                            random_state=0))])classifier is 1467.4735293388367 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.67      0.65      1455\n",
    "           1       0.67      0.64      0.66      1545\n",
    "\n",
    "    accuracy                           0.65      3000\n",
    "   macro avg       0.65      0.65      0.65      3000\n",
    "weighted avg       0.66      0.65      0.65      3000\n",
    "\n",
    "# RandomForestClassifier() with k=5 and 6. With 100% Data and std scaling.\n",
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('randomforestclassifier', RandomForestClassifier())])classifier is 167.23593544960022 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.57      0.62      0.59      1455\n",
    "           1       0.61      0.57      0.59      1545\n",
    "\n",
    "    accuracy                           0.59      3000\n",
    "   macro avg       0.59      0.59      0.59      3000\n",
    "weighted avg       0.59      0.59      0.59      3000\n",
    "\n",
    "# RandomForestClassifier() with k=5 and 6. With 90% Data and std scaling.\n",
    "Runtime of fitting Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('randomforestclassifier', RandomForestClassifier())])classifier is 178.086359500885 secs\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.55      0.60      0.57      1455\n",
    "           1       0.58      0.53      0.56      1545\n",
    "\n",
    "    accuracy                           0.56      3000\n",
    "   macro avg       0.56      0.56      0.56      3000\n",
    "weighted avg       0.57      0.56      0.56      3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.654 \n",
      "precision = 0.655 \n",
      "recall = 0.654 \n",
      "f1 = 0.654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(\"Confusion matrix\\n\")\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "# pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[930, 525],\n",
       "       [558, 987]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['True', 'False']\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                             display_labels=class_names,\n",
    "                             cmap=plt.cm.BuGn)\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "disp.confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of GridSearch HyperParam tuning of Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gaussiannb', GaussianNB())])classifier is 0.013000965118408203 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# clf?\n",
    "start = time.time()\n",
    "from sklearn.pipeline import Pipeline\n",
    "SVCpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('SVC',LinearSVC())])\n",
    "  \n",
    "# defining parameter range\n",
    "\n",
    "param_grid = {'SVC__C':np.arange(0.01,100,10)}\n",
    "  \n",
    "linearSVC = GridSearchCV(SVCpipe,param_grid,cv=5,return_train_score=True)\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of GridSearch HyperParam tuning of \"+ str(clf)+ f\"classifier is {end - start} secs\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "linearSVC.fit(X_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of fitting \"+ str(clf)+ f\"classifier is {end - start} secs\")\n",
    "\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(clf.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(clf.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linearSVC.predict(X_test)\n",
    "# print(\"Confusion matrix\\n\")\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "# pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime of GridSearchCV LinearSVC (random_state=0, tol=1e-05) classifier is 10416.215190410614 secs\n",
    "Best parameter after tuning: {'SVC__C': 0.01}\n",
    "\n",
    "Warnings: C:\\Users\\Bassem new\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, n_jobs=-1, refit = True, verbose = 3)\n",
    "\n",
    "\n",
    "#fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Runtime of GridSearch HyperParam tuning of \"+ str(grid)+ f\"classifier is {end - start} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61      2015\n",
      "           1       0.60      0.59      0.60      1985\n",
      "\n",
      "    accuracy                           0.60      4000\n",
      "   macro avg       0.60      0.60      0.60      4000\n",
      "weighted avg       0.60      0.60      0.60      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5LLSXIzhETp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1616679239831,
     "user": {
      "displayName": "Swiss Baz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXzlrRV6mp31muOP9-SkG2Bqe4yaRqjFrtEvNyUzQ=s64",
      "userId": "00750900217968553970"
     },
     "user_tz": -60
    },
    "id": "uOEeL7ODhETp",
    "outputId": "9239b0a4-b932-4655-9fce-3447d3073d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.601 \n",
      "precision = 0.600 \n",
      "recall = 0.601 \n",
      "f1 = 0.600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LinearSVC(random_state=0, tol=1e-5, C=0.01, max_iter=2500)) # Hyper Tuned\n",
    "accuracy = 0.590 \n",
    "precision = 0.590 \n",
    "recall = 0.590 \n",
    "f1 = 0.589\n",
    "\n",
    "\n",
    "SGDClassifier:\n",
    "accuracy = 0.568 \n",
    "precision = 0.568 \n",
    "recall = 0.568 \n",
    "f1 = 0.568\n",
    "\n",
    "\n",
    "KNeighborsClassifier(n_neighbors=4, weights='distance'):\n",
    "accuracy = 0.502 \n",
    "precision = 0.502 \n",
    "recall = 0.502 \n",
    "f1 = 0.502\n",
    "\n",
    "Logistic Regression with tf.idf layer: \n",
    "accuracy = 0.588 \n",
    "precision = 0.588 \n",
    "recall = 0.587 \n",
    "f1 = 0.588\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1616679245737,
     "user": {
      "displayName": "Swiss Baz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXzlrRV6mp31muOP9-SkG2Bqe4yaRqjFrtEvNyUzQ=s64",
      "userId": "00750900217968553970"
     },
     "user_tz": -60
    },
    "id": "jqvAWpGUhETp",
    "outputId": "e4185db8-9982-4c15-8246-f9f5a7eeff1d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1226,  789],\n",
       "       [ 809, 1176]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yy8YSWgmhETp"
   },
   "outputs": [],
   "source": [
    "# sn.heatmap(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')), annot=True,cmap=\"OrRd\")\n",
    "# dump(clf, './saved/clf.joblib') \n",
    "# clf = load('./saved/clf.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "BeIYSu7ZhETq"
   },
   "outputs": [],
   "source": [
    "# ! pip install natsort\n",
    "import natsort, os\n",
    "def get_files(directory,pattern):\n",
    "    '''\n",
    "    Get the files of a directory, this returns the files in sorted order,\n",
    "    Sort is very important as it assures DataFrame order\n",
    "    corresponding to the original data order\n",
    "    '''\n",
    "    # pl = glob.glob(directory+r\"\\*.txt\")\n",
    "    files = natsort.natsorted(os.listdir(directory))\n",
    "    # for p in files:\n",
    "    #     display(r\"\\n\" + p)\n",
    "    for path in files:\n",
    "        yield directory + r\"\\\\\" + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "fqurFUCNhETq"
   },
   "outputs": [],
   "source": [
    "pattern=\"*\"\n",
    "countsPath = r\"D:\\DataSet\\MULTI\\bow\\6mer\"\n",
    "files = []\n",
    "# Get files based on pattern and their sum of size\n",
    "for file in get_files(directory=countsPath,pattern=pattern):\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-59999.txt'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.array(files).reshape(6,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-0.txt',\n",
       "       'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-1.txt',\n",
       "       'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-2.txt', ...,\n",
       "       'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-9997.txt',\n",
       "       'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-9998.txt',\n",
       "       'D:\\\\DataSet\\\\MULTI\\\\bow\\\\6mer\\\\\\\\kmers-6-seqNb-9999.txt'],\n",
       "      dtype='<U50')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(l1[1][:].tolist())\n",
    "display(l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Parallel of DNAsequencing.ipynb",
   "provenance": [
    {
     "file_id": "1i18NqNHMNQn_ZW-JCNOdYdWAZBc747mY",
     "timestamp": 1616681546116
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
