{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import gc\n",
    "import timeit\n",
    "from Bio import SeqIO\n",
    "from joblib import dump, load\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import ipywidgets\n",
    "tqdm.pandas()\n",
    "from ipywidgets import IntProgress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 generate space separated sentences of kmers\n",
    "## Read kmers from disc \n",
    "\n",
    "# !!! This code is run once. \n",
    "# Result can be used to train LSTM on kmers\n",
    "# In step 3 we load processed data written on disk !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime for loading kmers from disk is 191.4085066318512 secs\n",
      "Runtime for conversion into space separated kmers  144.07870817184448 secs\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#     Conversion step 2: read generated kmers data from disc                  #\n",
    "###############################################################################\n",
    "\n",
    "#same number of splits/chunks from the first step\n",
    "k=10\n",
    "\n",
    "split = 6\n",
    "\n",
    "columnName=str(k)+\"mers\"\n",
    "# automatic garbage collector, helps free memory\n",
    "gc.enable()\n",
    "# gc.disable()\n",
    "\n",
    "l1=DataFrame()\n",
    "start = time.time()\n",
    "for i in range(0,split):\n",
    "    l1 = l1.append(pd.read_feather(r\"D:\\DataSet\\LSTMonBoW\\k\"+str(k)+\"-part-\"+str(i)+\"-kmer.feather\"))\n",
    "gc.collect()\n",
    "len(l1)\n",
    "\n",
    "end = time.time()\n",
    "#     total time taken\n",
    "print(f\"Runtime for loading kmers from disk is {end - start} secs\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "textword = list(l1[columnName]) # Form string\n",
    "for i in range(len(textword)): # String concatenates into text\n",
    "    textword[i] = ' '.join(textword[i])\n",
    "    \n",
    "end = time.time()\n",
    "#     total time taken\n",
    "print(f\"Runtime for conversion into space separated kmers  {end - start} secs\")\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "#   Write the space separated kmer sentences to disk to free the memory and   #\n",
    "#            load them in Step three to free memory                           #\n",
    "###############################################################################\n",
    "    \n",
    "with open(r\"D:\\DataSet\\LSTMonBoW\\spaced words-k\"+str(k), 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(textword, filehandle)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"D:\\DataSet\\LSTMonBoW\\spaced words-k\"+str(k), 'rb') as filehandle:\n",
    "#     # store the data as binary data stream\n",
    "#     textword = pickle.load(filehandle)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
